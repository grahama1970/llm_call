# Test Report - 2025-05-26 08:40:58

## Summary
- **Total Tests**: 29
- **Passed**: 17 (58.6%)
- **Failed**: 11 (37.9%)
- **Skipped**: 1 (3.4%)
- **Duration**: 32.62s

## Test Results

| Test Name | Description | Result | Status | Duration | Timestamp | Error Message |
|-----------|-------------|--------|--------|----------|-----------|---------------|
| test_ask_basic | Test basic ask command. | Test failed | Fail | 4.579s | 2025-05-26 08:41:02 | tests/llm_call/cli/test_cli_comprehensive.py:105: in test_ask_basic     assert "test" in result.outp... |
| test_ask_with_model | Test ask command with model selection. | Test failed | Fail | 2.859s | 2025-05-26 08:41:05 | tests/llm_call/cli/test_cli_comprehensive.py:118: in test_ask_with_model     assert "4" in result.ou... |
| test_ask_with_validation | Test ask command with validation. | Success | Pass | 3.214s | 2025-05-26 08:41:09 |  |
| test_ask_json_mode | Test ask command with JSON mode. | Skipped | Skip | 0.000s | 2025-05-26 08:41:09 |  |
| test_ask_with_system_prompt | Test ask command with system prompt. | Test failed | Fail | 3.027s | 2025-05-26 08:41:12 | tests/llm_call/cli/test_cli_comprehensive.py:159: in test_ask_with_system_prompt     assert "greetin... |
| test_ask_show_config | Test ask command with config display. | Success | Pass | 3.102s | 2025-05-26 08:41:15 |  |
| test_chat_basic | Test basic chat command. | Test failed | Fail | 0.006s | 2025-05-26 08:41:15 | tests/llm_call/cli/test_cli_comprehensive.py:187: in test_chat_basic     assert result.exit_code == ... |
| test_chat_with_system | Test chat with system prompt. | Test failed | Fail | 0.004s | 2025-05-26 08:41:15 | tests/llm_call/cli/test_cli_comprehensive.py:200: in test_chat_with_system     assert result.exit_co... |
| test_call_json_config | Test call command with JSON config. | Test failed | Fail | 3.239s | 2025-05-26 08:41:18 | tests/llm_call/cli/test_cli_comprehensive.py:212: in test_call_json_config     assert "hello" in res... |
| test_call_yaml_config | Test call command with YAML config. | Test failed | Fail | 2.831s | 2025-05-26 08:41:21 | tests/llm_call/cli/test_cli_comprehensive.py:219: in test_call_yaml_config     assert "42" in result... |
| test_call_with_overrides | Test call command with config overrides. | Test failed | Fail | 0.008s | 2025-05-26 08:41:21 | tests/llm_call/cli/test_cli_comprehensive.py:230: in test_call_with_overrides     assert result.exit... |
| test_models_list_all | Test listing all models. | Success | Pass | 0.012s | 2025-05-26 08:41:21 |  |
| test_models_filter_provider | Test filtering models by provider. | assert "ollama" in result.output.lower() | Fail | 0.005s | 2025-05-26 08:41:21 | tests/llm_call/cli/test_cli_comprehensive.py:253: in test_models_filter_provider     assert "ollama"... |
| test_validators_list | Test listing validation strategies. | Success | Pass | 0.011s | 2025-05-26 08:41:21 |  |
| test_config_example_json | Test generating example JSON config. | Success | Pass | 0.003s | 2025-05-26 08:41:21 |  |
| test_config_example_yaml | Test generating example YAML config. | Success | Pass | 0.006s | 2025-05-26 08:41:21 |  |
| test_generate_claude | Test Claude slash command generation. | Success | Pass | 0.008s | 2025-05-26 08:41:21 |  |
| test_generate_mcp_config | Test MCP config generation. | Success | Pass | 0.004s | 2025-05-26 08:41:21 |  |
| test_serve_mcp_help | Test serve-mcp command help. | Success | Pass | 0.007s | 2025-05-26 08:41:21 |  |
| test_test_command_no_files | Test 'test' command when no test files exist. | Success | Pass | 0.003s | 2025-05-26 08:41:21 |  |
| test_test_command_with_files | Test 'test' command with test files. | Success | Pass | 0.023s | 2025-05-26 08:41:21 |  |
| test_test_poc_help | Test test-poc command help. | Success | Pass | 0.008s | 2025-05-26 08:41:21 |  |
| test_readme_examples_exist | Test that commands mentioned in README exist in CLI. | Success | Pass | 0.009s | 2025-05-26 08:41:21 |  |
| test_readme_ask_examples | Test that README 'ask' examples work. | Success | Pass | 3.156s | 2025-05-26 08:41:24 |  |
| test_config_with_validation | Test using config file with validation. | Test failed | Fail | 3.003s | 2025-05-26 08:41:27 | tests/llm_call/cli/test_cli_comprehensive.py:467: in test_config_with_validation     assert "valid" ... |
| test_generate_then_use_commands | Test generating commands and verifying they're usable. | Success | Pass | 0.023s | 2025-05-26 08:41:27 |  |
| test_call_missing_config | Test call command with missing config file. | Success | Pass | 0.005s | 2025-05-26 08:41:27 |  |
| test_call_invalid_config_format | Test call command with unsupported config format. | Success | Pass | 0.005s | 2025-05-26 08:41:27 |  |
| test_ask_invalid_model | Test handling invalid model. | Test failed | Fail | 3.080s | 2025-05-26 08:41:30 | tests/llm_call/cli/test_cli_comprehensive.py:524: in test_ask_invalid_model     assert result.exit_c... |

## Test Distribution by Module

| Module | Total | Passed | Failed | Skipped |
|--------|-------|--------|--------|---------|
| tests/llm_call/cli/test_cli_comprehensive.py | 29 | 17 | 11 | 1 |