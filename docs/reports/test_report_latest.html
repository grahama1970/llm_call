<\!DOCTYPE html>
<html>
<head>
    <title>Test Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1, h2 {
            color: #333;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            background-color: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #4CAF50;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        /* Style status column (4th column) */
        td:nth-child(4) {
            font-weight: bold;
        }
        /* Color status text */
        td:nth-child(4):contains('Pass') {
            color: green;
        }
        tr td:nth-child(4) {
            color: green;
        }
        tr:has(td:nth-child(4):contains('Fail')) td:nth-child(4) {
            color: red;
        }
        tr:has(td:nth-child(4):contains('Skip')) td:nth-child(4) {
            color: orange;
        }
    </style>
    <script>
        // JavaScript to color status cells after page load
        window.onload = function() {
            var cells = document.querySelectorAll('td:nth-child(4)');
            cells.forEach(function(cell) {
                if (cell.textContent.includes('Pass')) {
                    cell.style.color = 'green';
                    cell.style.fontWeight = 'bold';
                } else if (cell.textContent.includes('Fail')) {
                    cell.style.color = 'red';
                    cell.style.fontWeight = 'bold';
                } else if (cell.textContent.includes('Skip')) {
                    cell.style.color = 'orange';
                    cell.style.fontWeight = 'bold';
                }
            });
        }
    </script>
</head>
<body>
<h1>Test Report - 2025-05-26 11:24:22</h1>
<h2>Summary</h2>
<ul>
<li><strong>Total Tests</strong>: 119</li>
<li><strong>Passed</strong>: 80 (67.2%)</li>
<li><strong>Failed</strong>: 10 (8.4%)</li>
<li><strong>Skipped</strong>: 29 (24.4%)</li>
<li><strong>Duration</strong>: 32.26s</li>
</ul>
<h2>Test Results</h2>
<table>
<thead>
<tr>
<th>Test Name</th>
<th>Description</th>
<th>Result</th>
<th>Status</th>
<th>Duration</th>
<th>Timestamp</th>
<th>Error Message</th>
</tr>
</thead>
<tbody>
<tr>
<td>test_ask_basic</td>
<td>Test basic ask command.</td>
<td>Success</td>
<td>Pass</td>
<td>0.518s</td>
<td>2025-05-26 11:24:24</td>
<td></td>
</tr>
<tr>
<td>test_ask_with_model</td>
<td>Test ask command with model selection.</td>
<td>Success</td>
<td>Pass</td>
<td>0.472s</td>
<td>2025-05-26 11:24:25</td>
<td></td>
</tr>
<tr>
<td>test_ask_with_validation</td>
<td>Test ask command with validation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.560s</td>
<td>2025-05-26 11:24:25</td>
<td></td>
</tr>
<tr>
<td>test_ask_json_mode</td>
<td>Test ask command with JSON mode.</td>
<td>Success</td>
<td>Pass</td>
<td>0.771s</td>
<td>2025-05-26 11:24:26</td>
<td></td>
</tr>
<tr>
<td>test_ask_with_system_prompt</td>
<td>Test ask command with system prompt.</td>
<td>Success</td>
<td>Pass</td>
<td>0.574s</td>
<td>2025-05-26 11:24:27</td>
<td></td>
</tr>
<tr>
<td>test_ask_show_config</td>
<td>Test ask command with config display.</td>
<td>Success</td>
<td>Pass</td>
<td>0.988s</td>
<td>2025-05-26 11:24:28</td>
<td></td>
</tr>
<tr>
<td>test_chat_basic</td>
<td>Test basic chat command.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.010s</td>
<td>2025-05-26 11:24:28</td>
<td>tests/llm_call/cli/test_cli_comprehensive.py:191: in test_chat_basic     assert result.exit_code == ...</td>
</tr>
<tr>
<td>test_chat_with_system</td>
<td>Test chat with system prompt.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.004s</td>
<td>2025-05-26 11:24:28</td>
<td>tests/llm_call/cli/test_cli_comprehensive.py:205: in test_chat_with_system     assert result.exit_co...</td>
</tr>
<tr>
<td>test_call_json_config</td>
<td>Test call command with JSON config.</td>
<td>Success</td>
<td>Pass</td>
<td>0.719s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_call_yaml_config</td>
<td>Test call command with YAML config.</td>
<td>Success</td>
<td>Pass</td>
<td>0.480s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_call_with_overrides</td>
<td>Test call command with config overrides.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.008s</td>
<td>2025-05-26 11:24:29</td>
<td>tests/llm_call/cli/test_cli_comprehensive.py:237: in test_call_with_overrides     assert result.exit...</td>
</tr>
<tr>
<td>test_models_list_all</td>
<td>Test listing all models.</td>
<td>Success</td>
<td>Pass</td>
<td>0.013s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_models_filter_provider</td>
<td>Test filtering models by provider.</td>
<td>Success</td>
<td>Pass</td>
<td>0.007s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_validators_list</td>
<td>Test listing validation strategies.</td>
<td>Success</td>
<td>Pass</td>
<td>0.015s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_config_example_json</td>
<td>Test generating example JSON config.</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_config_example_yaml</td>
<td>Test generating example YAML config.</td>
<td>Success</td>
<td>Pass</td>
<td>0.006s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_generate_claude</td>
<td>Test Claude slash command generation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.009s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_generate_mcp_config</td>
<td>Test MCP config generation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.072s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_serve_mcp_help</td>
<td>Test serve-mcp command help.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_test_command_no_files</td>
<td>Test 'test' command when no test files exist.</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_test_command_with_files</td>
<td>Test 'test' command with test files.</td>
<td>Success</td>
<td>Pass</td>
<td>0.024s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_test_poc_help</td>
<td>Test test-poc command help.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_readme_examples_exist</td>
<td>Test that commands mentioned in README exist in CLI.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:29</td>
<td></td>
</tr>
<tr>
<td>test_readme_ask_examples</td>
<td>Test that README 'ask' examples work.</td>
<td>Success</td>
<td>Pass</td>
<td>0.485s</td>
<td>2025-05-26 11:24:30</td>
<td></td>
</tr>
<tr>
<td>test_config_with_validation</td>
<td>Test using config file with validation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.472s</td>
<td>2025-05-26 11:24:30</td>
<td></td>
</tr>
<tr>
<td>test_generate_then_use_commands</td>
<td>Test generating commands and verifying they're usable.</td>
<td>Success</td>
<td>Pass</td>
<td>0.024s</td>
<td>2025-05-26 11:24:30</td>
<td></td>
</tr>
<tr>
<td>test_call_missing_config</td>
<td>Test call command with missing config file.</td>
<td>Success</td>
<td>Pass</td>
<td>0.006s</td>
<td>2025-05-26 11:24:30</td>
<td></td>
</tr>
<tr>
<td>test_call_invalid_config_format</td>
<td>Test call command with unsupported config format.</td>
<td>Success</td>
<td>Pass</td>
<td>0.005s</td>
<td>2025-05-26 11:24:30</td>
<td></td>
</tr>
<tr>
<td>test_ask_invalid_model</td>
<td>Test handling invalid model.</td>
<td>assert "error" in result.output.lower() or "Error" in result.output or result.exit_code != 0</td>
<td>Fail</td>
<td>3.182s</td>
<td>2025-05-26 11:24:33</td>
<td>tests/llm_call/cli/test_cli_comprehensive.py:535: in test_ask_invalid_model     assert "error" in re...</td>
</tr>
<tr>
<td>test_cli_uses_router_real</td>
<td>Test that CLI properly uses the router with real LLM.</td>
<td>Success</td>
<td>Pass</td>
<td>3.238s</td>
<td>2025-05-26 11:24:37</td>
<td></td>
</tr>
<tr>
<td>test_model_routing_patterns_real</td>
<td>Test different model routing patterns with real routers.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:37</td>
<td></td>
</tr>
<tr>
<td>test_validation_strategies_applied_real</td>
<td>Test that validation strategies are properly applied with real LLM.</td>
<td>Success</td>
<td>Pass</td>
<td>3.208s</td>
<td>2025-05-26 11:24:40</td>
<td></td>
</tr>
<tr>
<td>test_validation_with_real_response</td>
<td>Test validation with actual LLM response.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:40</td>
<td></td>
</tr>
<tr>
<td>test_retry_config_in_file</td>
<td>Test retry configuration via config file with real execution.</td>
<td>Test failed</td>
<td>Fail</td>
<td>1.125s</td>
<td>2025-05-26 11:24:41</td>
<td>tests/llm_call/cli/test_llm_integration.py:143: in test_retry_config_in_file     assert "test" in re...</td>
</tr>
<tr>
<td>test_openai_integration_real</td>
<td>Test OpenAI provider integration with real API.</td>
<td>Success</td>
<td>Pass</td>
<td>0.550s</td>
<td>2025-05-26 11:24:42</td>
<td></td>
</tr>
<tr>
<td>test_local_model_integration</td>
<td>Test local model integration.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:42</td>
<td></td>
</tr>
<tr>
<td>test_streaming_disabled_by_default</td>
<td>Test that streaming is disabled by default.</td>
<td>Success</td>
<td>Pass</td>
<td>2.845s</td>
<td>2025-05-26 11:24:44</td>
<td></td>
</tr>
<tr>
<td>test_config_priority_real</td>
<td>Test configuration priority (CLI &gt; file) with real LLM.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.007s</td>
<td>2025-05-26 11:24:44</td>
<td>tests/llm_call/cli/test_llm_integration.py:214: in test_config_priority_real     assert result.exit_...</td>
</tr>
<tr>
<td>test_system_prompt_handling_real</td>
<td>Test system prompt is properly added to messages with real LLM.</td>
<td>Success</td>
<td>Pass</td>
<td>3.174s</td>
<td>2025-05-26 11:24:48</td>
<td></td>
</tr>
<tr>
<td>test_llm_error_propagation_real</td>
<td>Test that LLM errors are properly handled with invalid model.</td>
<td>Test failed</td>
<td>Fail</td>
<td>3.038s</td>
<td>2025-05-26 11:24:51</td>
<td>tests/llm_call/cli/test_llm_integration.py:241: in test_llm_error_propagation_real     assert result...</td>
</tr>
<tr>
<td>test_validation_error_handling</td>
<td>Test validation error handling with real validator.</td>
<td>Success</td>
<td>Pass</td>
<td>0.031s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_generate_mcp_config_structure</td>
<td>Test that generated MCP config has correct structure.</td>
<td>Success</td>
<td>Pass</td>
<td>0.007s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_mcp_tool_definitions</td>
<td>Test that MCP tools are properly defined.</td>
<td>Success</td>
<td>Pass</td>
<td>0.006s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_mcp_parameter_types</td>
<td>Test that parameter types are correctly mapped.</td>
<td>assert properties["max_tokens"]["type"] == "integer"</td>
<td>Fail</td>
<td>0.005s</td>
<td>2025-05-26 11:24:51</td>
<td>tests/llm_call/cli/test_mcp_features.py:169: in test_mcp_parameter_types     assert properties["max_...</td>
</tr>
<tr>
<td>test_serve_mcp_initialization</td>
<td>Test MCP server initialization.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.000s</td>
<td>2025-05-26 11:24:51</td>
<td>../../../.local/share/uv/python/cpython-3.10.11-linux-x86_64-gnu/lib/python3.10/unittest/mock.py:137...</td>
</tr>
<tr>
<td>test_serve_mcp_missing_dependency</td>
<td>Test error when FastMCP is not installed.</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_serve_mcp_debug_mode</td>
<td>Test MCP server in debug mode.</td>
<td>Test failed</td>
<td>Fail</td>
<td>0.000s</td>
<td>2025-05-26 11:24:51</td>
<td>../../../.local/share/uv/python/cpython-3.10.11-linux-x86_64-gnu/lib/python3.10/unittest/mock.py:137...</td>
</tr>
<tr>
<td>test_add_slash_mcp_commands</td>
<td>Test adding slash/MCP commands to a CLI app.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_generate_claude_via_mixin</td>
<td>Test Claude generation via mixin.</td>
<td>Success</td>
<td>Pass</td>
<td>0.002s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_generate_mcp_via_mixin</td>
<td>Test MCP config generation via mixin.</td>
<td>Success</td>
<td>Pass</td>
<td>0.002s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_slash_mcp_decorator</td>
<td>Test the @slash_mcp_cli decorator.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_claude_slash_command_format</td>
<td>Test that Claude slash commands have correct format.</td>
<td>Success</td>
<td>Pass</td>
<td>0.010s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_claude_command_skip_list</td>
<td>Test that certain commands are skipped for Claude.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_mcp_tool_execution_mapping</td>
<td>Test that MCP tools map correctly to CLI execution.</td>
<td>Success</td>
<td>Pass</td>
<td>0.004s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_full_mcp_generation_workflow</td>
<td>Test generating both Claude and MCP configs.</td>
<td>Success</td>
<td>Pass</td>
<td>0.011s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_mcp_parameter_consistency</td>
<td>Test that parameters are consistent across formats.</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_serve_mcp_command_exists</td>
<td>Test that serve-mcp command is available.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_serve_mcp_help</td>
<td>Test serve-mcp help output.</td>
<td>Success</td>
<td>Pass</td>
<td>0.007s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_generate_claude_command</td>
<td>Test Claude slash command generation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_models_command_as_tool</td>
<td>Test that models command can be used as MCP tool.</td>
<td>Success</td>
<td>Pass</td>
<td>0.075s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_validators_command_as_tool</td>
<td>Test that validators command can be used as MCP tool.</td>
<td>Success</td>
<td>Pass</td>
<td>0.010s</td>
<td>2025-05-26 11:24:51</td>
<td></td>
</tr>
<tr>
<td>test_mcp_llm_call_format</td>
<td>Test that MCP can format LLM calls correctly.</td>
<td>Success</td>
<td>Pass</td>
<td>3.042s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_config_building</td>
<td>Test configuration building from various sources.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_config_file_loading</td>
<td>Test loading configurations from files.</td>
<td>Success</td>
<td>Pass</td>
<td>0.001s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_slash_command_generation</td>
<td>Test slash command configuration generation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_validation_integration</td>
<td>Test validation strategy integration.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_basic_llm_request</td>
<td>Test basic LLM request with real provider.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_response_format</td>
<td>Test JSON response format with real LLM.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_router_integration</td>
<td>Test router correctly selects providers.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_validation_integration</td>
<td>Test validation with real LLM responses.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_error_handling</td>
<td>Test error handling with invalid model.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_temperature_effects</td>
<td>Test temperature parameter effects on responses.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_system_message_handling</td>
<td>Test system message handling.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_format_detection</td>
<td>Test enhanced format detection.</td>
<td>Success</td>
<td>Pass</td>
<td>0.030s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_api_formatting</td>
<td>Test API-specific formatting.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_metadata_encoding</td>
<td>Test image encoding with metadata.</td>
<td>Success</td>
<td>Pass</td>
<td>0.004s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_integration</td>
<td>Test integration with existing process_image_input.</td>
<td>Success</td>
<td>Pass</td>
<td>0.002s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_exponential_backoff_calculation</td>
<td>Test exponential backoff delay calculation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_exponential_backoff_with_jitter</td>
<td>Test exponential backoff with jitter.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_circuit_breaker_state_transitions</td>
<td>Test circuit breaker state transitions.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_circuit_breaker_window</td>
<td>Test circuit breaker failure window.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_circuit_breaker_excluded_exceptions</td>
<td>Test circuit breaker excludes certain exceptions.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_retry_with_exponential_backoff_real</td>
<td>Test retry mechanism with real LLM calls and exponential backoff.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_circuit_breaker_integration_real</td>
<td>Test circuit breaker with real failing LLM calls.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_performance_benchmark</td>
<td>Test performance of delay calculation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.008s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_max_model_routing</td>
<td>Test that max/* models are routed to Claude proxy.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_claude_max_variants</td>
<td>Test additional max model patterns from POC.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_non_max_model_routing</td>
<td>Test that non-max models route to LiteLLM.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_question_to_messages_conversion</td>
<td>Test conversion of question format to messages format.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_response_format_handling</td>
<td>Test that response_format is preserved for max models.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_performance_benchmark</td>
<td>Test routing performance meets POC benchmark (&lt;50ms).</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_basic_validation</td>
<td>Test basic validation strategies.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_ai_validation</td>
<td>Test AI-assisted validation.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_mcp_configuration</td>
<td>Test MCP configuration passing.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_agent_task_validation</td>
<td>Test generic agent task validation.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_validation_registry</td>
<td>Test validation strategy registry.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_real_llm_validation</td>
<td>Test AI validators with real LLM calls</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_realistic_validation</td>
<td>Test validators with real LLM responses</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_with_real_llm</td>
<td>Test validators with actual LLM calls</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_extraction_from_markdown</td>
<td>Test extracting JSON from markdown code blocks.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_extraction_from_generic_block</td>
<td>Test extracting JSON from generic code blocks.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_extraction_raw</td>
<td>Test extracting raw JSON without code blocks.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_schema_validation</td>
<td>Test JSON schema validation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.003s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_field_presence_validation</td>
<td>Test field presence validation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_nested_field_validation</td>
<td>Test nested field validation.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_error_recovery</td>
<td>Test JSON error recovery.</td>
<td>Success</td>
<td>Pass</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_convenience_functions</td>
<td>Test convenience functions.</td>
<td>Success</td>
<td>Pass</td>
<td>0.002s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_performance</td>
<td>Test performance meets target (&lt;10ms).</td>
<td>Success</td>
<td>Pass</td>
<td>0.004s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_first_prompt</td>
<td>Test the simplest Claude proxy call.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_basic_mcp_call</td>
<td>Test 1: Basic call to Claude proxy with default MCP config.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_custom_mcp_config</td>
<td>Test 2: Custom MCP config with only specific tools.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_ai_validation_contradiction</td>
<td>Test 3: AI-assisted validation for contradiction checking.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_code_validation</td>
<td>Test 4: Code syntax validation with agent task.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_staged_retry_with_tools</td>
<td>Test 5: Multi-stage retry with tool suggestion.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_json_validation</td>
<td>Test 6: JSON response validation with field checks.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_openai_text</td>
<td>Test OpenAI text generation.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_openai_json</td>
<td>Test OpenAI JSON generation with validation.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_max_proxy</td>
<td>Test max/* model through proxy.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
<tr>
<td>test_multimodal</td>
<td>Test multimodal with local image.</td>
<td>Skipped</td>
<td>Skip</td>
<td>0.000s</td>
<td>2025-05-26 11:24:54</td>
<td></td>
</tr>
</tbody>
</table>
<h2>Test Distribution by Module</h2>
<table>
<thead>
<tr>
<th>Module</th>
<th>Total</th>
<th>Passed</th>
<th>Failed</th>
<th>Skipped</th>
</tr>
</thead>
<tbody>
<tr>
<td>tests/llm_call/cli/test_cli_comprehensive.py</td>
<td>29</td>
<td>25</td>
<td>4</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/cli/test_llm_integration.py</td>
<td>12</td>
<td>8</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>tests/llm_call/cli/test_mcp_features.py</td>
<td>15</td>
<td>12</td>
<td>3</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/cli/test_mcp_features_real.py</td>
<td>6</td>
<td>6</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/cli/test_unified_integration.py</td>
<td>4</td>
<td>4</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/core/test_core_integration.py</td>
<td>7</td>
<td>0</td>
<td>0</td>
<td>7</td>
</tr>
<tr>
<td>tests/llm_call/core/test_image_encoding_enhancements.py</td>
<td>4</td>
<td>4</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/core/test_retry_exponential.py</td>
<td>8</td>
<td>6</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>tests/llm_call/core/test_router.py</td>
<td>6</td>
<td>6</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/core/test_validation_integration.py</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>5</td>
</tr>
<tr>
<td>tests/llm_call/core/validation/test_ai_validator_real_llm.py</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>tests/llm_call/core/validation/test_ai_validator_realistic.py</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>tests/llm_call/core/validation/test_ai_validator_with_llm.py</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>tests/llm_call/core/validation/test_json_validators.py</td>
<td>9</td>
<td>9</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>tests/llm_call/proof_of_concept/test_first_prompt.py</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>tests/llm_call/proof_of_concept/test_v4_implementation.py</td>
<td>6</td>
<td>0</td>
<td>0</td>
<td>6</td>
</tr>
<tr>
<td>tests/llm_call/proof_of_concept/test_working_models.py</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>4</td>
</tr>
</tbody>
</table>
</body>
</html>