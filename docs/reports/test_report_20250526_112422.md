# Test Report - 2025-05-26 11:24:22

## Summary
- **Total Tests**: 119
- **Passed**: 80 (67.2%)
- **Failed**: 10 (8.4%)
- **Skipped**: 29 (24.4%)
- **Duration**: 32.26s

## Test Results

| Test Name | Description | Result | Status | Duration | Timestamp | Error Message |
|-----------|-------------|--------|--------|----------|-----------|---------------|
| test_ask_basic | Test basic ask command. | Success | Pass | 0.518s | 2025-05-26 11:24:24 |  |
| test_ask_with_model | Test ask command with model selection. | Success | Pass | 0.472s | 2025-05-26 11:24:25 |  |
| test_ask_with_validation | Test ask command with validation. | Success | Pass | 0.560s | 2025-05-26 11:24:25 |  |
| test_ask_json_mode | Test ask command with JSON mode. | Success | Pass | 0.771s | 2025-05-26 11:24:26 |  |
| test_ask_with_system_prompt | Test ask command with system prompt. | Success | Pass | 0.574s | 2025-05-26 11:24:27 |  |
| test_ask_show_config | Test ask command with config display. | Success | Pass | 0.988s | 2025-05-26 11:24:28 |  |
| test_chat_basic | Test basic chat command. | Test failed | Fail | 0.010s | 2025-05-26 11:24:28 | tests/llm_call/cli/test_cli_comprehensive.py:191: in test_chat_basic     assert result.exit_code == ... |
| test_chat_with_system | Test chat with system prompt. | Test failed | Fail | 0.004s | 2025-05-26 11:24:28 | tests/llm_call/cli/test_cli_comprehensive.py:205: in test_chat_with_system     assert result.exit_co... |
| test_call_json_config | Test call command with JSON config. | Success | Pass | 0.719s | 2025-05-26 11:24:29 |  |
| test_call_yaml_config | Test call command with YAML config. | Success | Pass | 0.480s | 2025-05-26 11:24:29 |  |
| test_call_with_overrides | Test call command with config overrides. | Test failed | Fail | 0.008s | 2025-05-26 11:24:29 | tests/llm_call/cli/test_cli_comprehensive.py:237: in test_call_with_overrides     assert result.exit... |
| test_models_list_all | Test listing all models. | Success | Pass | 0.013s | 2025-05-26 11:24:29 |  |
| test_models_filter_provider | Test filtering models by provider. | Success | Pass | 0.007s | 2025-05-26 11:24:29 |  |
| test_validators_list | Test listing validation strategies. | Success | Pass | 0.015s | 2025-05-26 11:24:29 |  |
| test_config_example_json | Test generating example JSON config. | Success | Pass | 0.003s | 2025-05-26 11:24:29 |  |
| test_config_example_yaml | Test generating example YAML config. | Success | Pass | 0.006s | 2025-05-26 11:24:29 |  |
| test_generate_claude | Test Claude slash command generation. | Success | Pass | 0.009s | 2025-05-26 11:24:29 |  |
| test_generate_mcp_config | Test MCP config generation. | Success | Pass | 0.072s | 2025-05-26 11:24:29 |  |
| test_serve_mcp_help | Test serve-mcp command help. | Success | Pass | 0.008s | 2025-05-26 11:24:29 |  |
| test_test_command_no_files | Test 'test' command when no test files exist. | Success | Pass | 0.003s | 2025-05-26 11:24:29 |  |
| test_test_command_with_files | Test 'test' command with test files. | Success | Pass | 0.024s | 2025-05-26 11:24:29 |  |
| test_test_poc_help | Test test-poc command help. | Success | Pass | 0.008s | 2025-05-26 11:24:29 |  |
| test_readme_examples_exist | Test that commands mentioned in README exist in CLI. | Success | Pass | 0.008s | 2025-05-26 11:24:29 |  |
| test_readme_ask_examples | Test that README 'ask' examples work. | Success | Pass | 0.485s | 2025-05-26 11:24:30 |  |
| test_config_with_validation | Test using config file with validation. | Success | Pass | 0.472s | 2025-05-26 11:24:30 |  |
| test_generate_then_use_commands | Test generating commands and verifying they're usable. | Success | Pass | 0.024s | 2025-05-26 11:24:30 |  |
| test_call_missing_config | Test call command with missing config file. | Success | Pass | 0.006s | 2025-05-26 11:24:30 |  |
| test_call_invalid_config_format | Test call command with unsupported config format. | Success | Pass | 0.005s | 2025-05-26 11:24:30 |  |
| test_ask_invalid_model | Test handling invalid model. | assert "error" in result.output.lower() or "Error" in result.output or result.exit_code != 0 | Fail | 3.182s | 2025-05-26 11:24:33 | tests/llm_call/cli/test_cli_comprehensive.py:535: in test_ask_invalid_model     assert "error" in re... |
| test_cli_uses_router_real | Test that CLI properly uses the router with real LLM. | Success | Pass | 3.238s | 2025-05-26 11:24:37 |  |
| test_model_routing_patterns_real | Test different model routing patterns with real routers. | Success | Pass | 0.000s | 2025-05-26 11:24:37 |  |
| test_validation_strategies_applied_real | Test that validation strategies are properly applied with real LLM. | Success | Pass | 3.208s | 2025-05-26 11:24:40 |  |
| test_validation_with_real_response | Test validation with actual LLM response. | Skipped | Skip | 0.000s | 2025-05-26 11:24:40 |  |
| test_retry_config_in_file | Test retry configuration via config file with real execution. | Test failed | Fail | 1.125s | 2025-05-26 11:24:41 | tests/llm_call/cli/test_llm_integration.py:143: in test_retry_config_in_file     assert "test" in re... |
| test_openai_integration_real | Test OpenAI provider integration with real API. | Success | Pass | 0.550s | 2025-05-26 11:24:42 |  |
| test_local_model_integration | Test local model integration. | Success | Pass | 0.000s | 2025-05-26 11:24:42 |  |
| test_streaming_disabled_by_default | Test that streaming is disabled by default. | Success | Pass | 2.845s | 2025-05-26 11:24:44 |  |
| test_config_priority_real | Test configuration priority (CLI > file) with real LLM. | Test failed | Fail | 0.007s | 2025-05-26 11:24:44 | tests/llm_call/cli/test_llm_integration.py:214: in test_config_priority_real     assert result.exit_... |
| test_system_prompt_handling_real | Test system prompt is properly added to messages with real LLM. | Success | Pass | 3.174s | 2025-05-26 11:24:48 |  |
| test_llm_error_propagation_real | Test that LLM errors are properly handled with invalid model. | Test failed | Fail | 3.038s | 2025-05-26 11:24:51 | tests/llm_call/cli/test_llm_integration.py:241: in test_llm_error_propagation_real     assert result... |
| test_validation_error_handling | Test validation error handling with real validator. | Success | Pass | 0.031s | 2025-05-26 11:24:51 |  |
| test_generate_mcp_config_structure | Test that generated MCP config has correct structure. | Success | Pass | 0.007s | 2025-05-26 11:24:51 |  |
| test_mcp_tool_definitions | Test that MCP tools are properly defined. | Success | Pass | 0.006s | 2025-05-26 11:24:51 |  |
| test_mcp_parameter_types | Test that parameter types are correctly mapped. | assert properties["max_tokens"]["type"] == "integer" | Fail | 0.005s | 2025-05-26 11:24:51 | tests/llm_call/cli/test_mcp_features.py:169: in test_mcp_parameter_types     assert properties["max_... |
| test_serve_mcp_initialization | Test MCP server initialization. | Test failed | Fail | 0.000s | 2025-05-26 11:24:51 | ../../../.local/share/uv/python/cpython-3.10.11-linux-x86_64-gnu/lib/python3.10/unittest/mock.py:137... |
| test_serve_mcp_missing_dependency | Test error when FastMCP is not installed. | Success | Pass | 0.003s | 2025-05-26 11:24:51 |  |
| test_serve_mcp_debug_mode | Test MCP server in debug mode. | Test failed | Fail | 0.000s | 2025-05-26 11:24:51 | ../../../.local/share/uv/python/cpython-3.10.11-linux-x86_64-gnu/lib/python3.10/unittest/mock.py:137... |
| test_add_slash_mcp_commands | Test adding slash/MCP commands to a CLI app. | Success | Pass | 0.000s | 2025-05-26 11:24:51 |  |
| test_generate_claude_via_mixin | Test Claude generation via mixin. | Success | Pass | 0.002s | 2025-05-26 11:24:51 |  |
| test_generate_mcp_via_mixin | Test MCP config generation via mixin. | Success | Pass | 0.002s | 2025-05-26 11:24:51 |  |
| test_slash_mcp_decorator | Test the @slash_mcp_cli decorator. | Success | Pass | 0.000s | 2025-05-26 11:24:51 |  |
| test_claude_slash_command_format | Test that Claude slash commands have correct format. | Success | Pass | 0.010s | 2025-05-26 11:24:51 |  |
| test_claude_command_skip_list | Test that certain commands are skipped for Claude. | Success | Pass | 0.008s | 2025-05-26 11:24:51 |  |
| test_mcp_tool_execution_mapping | Test that MCP tools map correctly to CLI execution. | Success | Pass | 0.004s | 2025-05-26 11:24:51 |  |
| test_full_mcp_generation_workflow | Test generating both Claude and MCP configs. | Success | Pass | 0.011s | 2025-05-26 11:24:51 |  |
| test_mcp_parameter_consistency | Test that parameters are consistent across formats. | Success | Pass | 0.003s | 2025-05-26 11:24:51 |  |
| test_serve_mcp_command_exists | Test that serve-mcp command is available. | Success | Pass | 0.008s | 2025-05-26 11:24:51 |  |
| test_serve_mcp_help | Test serve-mcp help output. | Success | Pass | 0.007s | 2025-05-26 11:24:51 |  |
| test_generate_claude_command | Test Claude slash command generation. | Success | Pass | 0.008s | 2025-05-26 11:24:51 |  |
| test_models_command_as_tool | Test that models command can be used as MCP tool. | Success | Pass | 0.075s | 2025-05-26 11:24:51 |  |
| test_validators_command_as_tool | Test that validators command can be used as MCP tool. | Success | Pass | 0.010s | 2025-05-26 11:24:51 |  |
| test_mcp_llm_call_format | Test that MCP can format LLM calls correctly. | Success | Pass | 3.042s | 2025-05-26 11:24:54 |  |
| test_config_building | Test configuration building from various sources. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_config_file_loading | Test loading configurations from files. | Success | Pass | 0.001s | 2025-05-26 11:24:54 |  |
| test_slash_command_generation | Test slash command configuration generation. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_validation_integration | Test validation strategy integration. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_basic_llm_request | Test basic LLM request with real provider. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_response_format | Test JSON response format with real LLM. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_router_integration | Test router correctly selects providers. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_validation_integration | Test validation with real LLM responses. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_error_handling | Test error handling with invalid model. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_temperature_effects | Test temperature parameter effects on responses. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_system_message_handling | Test system message handling. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_format_detection | Test enhanced format detection. | Success | Pass | 0.030s | 2025-05-26 11:24:54 |  |
| test_api_formatting | Test API-specific formatting. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_metadata_encoding | Test image encoding with metadata. | Success | Pass | 0.004s | 2025-05-26 11:24:54 |  |
| test_integration | Test integration with existing process_image_input. | Success | Pass | 0.002s | 2025-05-26 11:24:54 |  |
| test_exponential_backoff_calculation | Test exponential backoff delay calculation. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_exponential_backoff_with_jitter | Test exponential backoff with jitter. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_circuit_breaker_state_transitions | Test circuit breaker state transitions. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_circuit_breaker_window | Test circuit breaker failure window. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_circuit_breaker_excluded_exceptions | Test circuit breaker excludes certain exceptions. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_retry_with_exponential_backoff_real | Test retry mechanism with real LLM calls and exponential backoff. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_circuit_breaker_integration_real | Test circuit breaker with real failing LLM calls. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_performance_benchmark | Test performance of delay calculation. | Success | Pass | 0.008s | 2025-05-26 11:24:54 |  |
| test_max_model_routing | Test that max/* models are routed to Claude proxy. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_claude_max_variants | Test additional max model patterns from POC. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_non_max_model_routing | Test that non-max models route to LiteLLM. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_question_to_messages_conversion | Test conversion of question format to messages format. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_response_format_handling | Test that response_format is preserved for max models. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_performance_benchmark | Test routing performance meets POC benchmark (<50ms). | Success | Pass | 0.003s | 2025-05-26 11:24:54 |  |
| test_basic_validation | Test basic validation strategies. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_ai_validation | Test AI-assisted validation. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_mcp_configuration | Test MCP configuration passing. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_agent_task_validation | Test generic agent task validation. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_validation_registry | Test validation strategy registry. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_real_llm_validation | Test AI validators with real LLM calls | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_realistic_validation | Test validators with real LLM responses | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_with_real_llm | Test validators with actual LLM calls | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_extraction_from_markdown | Test extracting JSON from markdown code blocks. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_extraction_from_generic_block | Test extracting JSON from generic code blocks. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_extraction_raw | Test extracting raw JSON without code blocks. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_schema_validation | Test JSON schema validation. | Success | Pass | 0.003s | 2025-05-26 11:24:54 |  |
| test_field_presence_validation | Test field presence validation. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_nested_field_validation | Test nested field validation. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_error_recovery | Test JSON error recovery. | Success | Pass | 0.000s | 2025-05-26 11:24:54 |  |
| test_convenience_functions | Test convenience functions. | Success | Pass | 0.002s | 2025-05-26 11:24:54 |  |
| test_performance | Test performance meets target (<10ms). | Success | Pass | 0.004s | 2025-05-26 11:24:54 |  |
| test_first_prompt | Test the simplest Claude proxy call. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_basic_mcp_call | Test 1: Basic call to Claude proxy with default MCP config. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_custom_mcp_config | Test 2: Custom MCP config with only specific tools. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_ai_validation_contradiction | Test 3: AI-assisted validation for contradiction checking. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_code_validation | Test 4: Code syntax validation with agent task. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_staged_retry_with_tools | Test 5: Multi-stage retry with tool suggestion. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_json_validation | Test 6: JSON response validation with field checks. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_openai_text | Test OpenAI text generation. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_openai_json | Test OpenAI JSON generation with validation. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_max_proxy | Test max/* model through proxy. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |
| test_multimodal | Test multimodal with local image. | Skipped | Skip | 0.000s | 2025-05-26 11:24:54 |  |

## Test Distribution by Module

| Module | Total | Passed | Failed | Skipped |
|--------|-------|--------|--------|---------|
| tests/llm_call/cli/test_cli_comprehensive.py | 29 | 25 | 4 | 0 |
| tests/llm_call/cli/test_llm_integration.py | 12 | 8 | 3 | 1 |
| tests/llm_call/cli/test_mcp_features.py | 15 | 12 | 3 | 0 |
| tests/llm_call/cli/test_mcp_features_real.py | 6 | 6 | 0 | 0 |
| tests/llm_call/cli/test_unified_integration.py | 4 | 4 | 0 | 0 |
| tests/llm_call/core/test_core_integration.py | 7 | 0 | 0 | 7 |
| tests/llm_call/core/test_image_encoding_enhancements.py | 4 | 4 | 0 | 0 |
| tests/llm_call/core/test_retry_exponential.py | 8 | 6 | 0 | 2 |
| tests/llm_call/core/test_router.py | 6 | 6 | 0 | 0 |
| tests/llm_call/core/test_validation_integration.py | 5 | 0 | 0 | 5 |
| tests/llm_call/core/validation/test_ai_validator_real_llm.py | 1 | 0 | 0 | 1 |
| tests/llm_call/core/validation/test_ai_validator_realistic.py | 1 | 0 | 0 | 1 |
| tests/llm_call/core/validation/test_ai_validator_with_llm.py | 1 | 0 | 0 | 1 |
| tests/llm_call/core/validation/test_json_validators.py | 9 | 9 | 0 | 0 |
| tests/llm_call/proof_of_concept/test_first_prompt.py | 1 | 0 | 0 | 1 |
| tests/llm_call/proof_of_concept/test_v4_implementation.py | 6 | 0 | 0 | 6 |
| tests/llm_call/proof_of_concept/test_working_models.py | 4 | 0 | 0 | 4 |